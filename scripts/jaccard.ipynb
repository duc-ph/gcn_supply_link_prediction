{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 3.12.3\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>Supplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>AAPICO Hitech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>ABC Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>Adient plc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>AGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>Aisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51358</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>voestalpine Rotec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51359</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Xiangyang Sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51360</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yakumo Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51361</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yamashita Rubber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51362</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yoshino Press</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51363 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer              Supplier\n",
       "0        Volvo         AAPICO Hitech\n",
       "1        Volvo      ABC Technologies\n",
       "2        Volvo            Adient plc\n",
       "3        Volvo                   AGC\n",
       "4        Volvo                 Aisin\n",
       "...        ...                   ...\n",
       "51358  Unipres     voestalpine Rotec\n",
       "51359  Unipres     Xiangyang Sunrise\n",
       "51360  Unipres  Yakumo Manufacturing\n",
       "51361  Unipres      Yamashita Rubber\n",
       "51362  Unipres         Yoshino Press\n",
       "\n",
       "[51363 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE run from scripts directory!\n",
    "#read in the edge data\n",
    "df = pd.read_csv('../data/edges.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the edges into integer encodings, rather than text labels\n",
    "all_suppliers = set(df['Customer'].tolist() + df['Supplier'].tolist())\n",
    "nametoi = {name: i for i, name in enumerate(all_suppliers)}\n",
    "edges = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    supplier1, supplier2 = row\n",
    "    idx1, idx2 = nametoi[supplier1], nametoi[supplier2]\n",
    "    edges.append((idx1, idx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38640 positive edges in the training set and 9659 positive edges in the test set\n"
     ]
    }
   ],
   "source": [
    "#get a training-test split of edges\n",
    "test_split = .20 #the percentage of edges to go into the test set\n",
    "edges = list(G.edges())\n",
    "#randomly sample the positive edges to get the specified percentage of test edges\n",
    "test_edges = random.sample(edges, int(G.number_of_edges()*test_split))\n",
    "#make a graph out of test edges, so we can remove edges from training set\n",
    "test_G = nx.Graph()\n",
    "test_G.add_edges_from(test_edges)\n",
    "#take the positive edges that are not in the test set as the training set\n",
    "train_edges = [edge for edge in edges if edge not in test_edges]\n",
    "train_G = G.copy()\n",
    "train_G.remove_edges_from(test_G.edges()) #remove the edges that are in the test set\n",
    "print(f'There are {train_G.number_of_edges()} positive edges in the training set and {test_G.number_of_edges()} positive edges in the test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all of the negative edges that exist in G\n",
    "non_edges = list(nx.non_edges(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 112849590 non-edges in the graph\n"
     ]
    }
   ],
   "source": [
    "print(f'there are {len(non_edges)} non-edges in the graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the n_times_as_many_pos_test_edges more negative edges as there are positive in the test set\n",
    "n_times_as_many_pos_test_edges = 4\n",
    "non_edges_test = random.sample(non_edges, len(test_edges)*n_times_as_many_pos_test_edges) #randomly sample from the collected negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 38636 negative edges and 9659 positive edges\n"
     ]
    }
   ],
   "source": [
    "print(f'test set has {len(non_edges_test)} negative edges and {len(test_edges)} positive edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the labels for the test set\n",
    "test_edges_labels = [True]*len(test_edges) #all of these are positive labels (they did exist in the graph)\n",
    "non_edge_test_labels = [False]*len(non_edges_test) #all of these are negative labels (they did NOT exist in the graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge non_edge labels into test labels \n",
    "# (nx.jaccard_coefficient outputs predictions in order, so we can just extend them like this)\n",
    "test_edges_labels.extend(non_edge_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge non edge test into the test edge set\n",
    "# (nx.jaccard_coefficient outputs predictions in order, so we can just extend them like this)\n",
    "test_edges.extend(non_edges_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the jaccard prectiction on the test set, given the training graph\n",
    "preds = list(nx.jaccard_coefficient(train_G, test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results to csv so we can save them and use them in process_jaccard_results.py\n",
    "with open('../data/jaccard_results.csv', 'w') as csvFile:    \n",
    "    for i in range(len(test_edges_labels)):\n",
    "        csvFile.write(f'{test_edges_labels[i]},{preds[i][2]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos/neg ratio 1/4:\n",
      "AUC score: 0.6671504515812371\n",
      "Best F1 score: 0.3333333333333333\n",
      "Precision for best F1 score: 0.2\n",
      "=============\n",
      "pos/neg ratio 1/3:\n",
      "AUC score: 0.6673903932640858\n",
      "Best F1 score: 0.4\n",
      "Precision for best F1 score: 0.25\n",
      "=============\n",
      "pos/neg ratio 1/2:\n",
      "AUC score: 0.6666060193760563\n",
      "Best F1 score: 0.5\n",
      "Precision for best F1 score: 0.3333333333333333\n",
      "=============\n",
      "pos/neg ratio 1/1:\n",
      "AUC score: 0.6673988216100489\n",
      "Best F1 score: 0.6666666666666666\n",
      "Precision for best F1 score: 0.5\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "test_positive_edges = random.sample(edges, int(G.number_of_edges()*test_split))\n",
    "\n",
    "all_auc = []\n",
    "all_f1 = []\n",
    "all_precision = []\n",
    "\n",
    "for n_times_as_many_pos_test_edges in reversed(range(1, 5)):\n",
    "    test_negative_edges = random.sample(non_edges, len(test_positive_edges) * n_times_as_many_pos_test_edges)\n",
    "    test_label = [True] * len(test_positive_edges) + [False] * len(test_negative_edges)\n",
    "    all_test_edges = test_positive_edges + test_negative_edges\n",
    "\n",
    "    preds = list(nx.jaccard_coefficient(train_G, all_test_edges))\n",
    "    probs = [x[2] for x in preds]\n",
    "\n",
    "    auc = roc_auc_score(test_label, probs)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_precision = 0\n",
    "    thresholds = np.arange(0, 1.01, 0.01)  # Generate thresholds from 0 to 1\n",
    "    for threshold in thresholds:\n",
    "        predicted_labels = [p >= threshold for p in probs]\n",
    "        f1 = f1_score(test_label, predicted_labels)\n",
    "        precision = precision_score(test_label, predicted_labels)\n",
    "\n",
    "        # Track the best F1 score and corresponding threshold\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_precision = precision\n",
    "\n",
    "    all_f1.append(best_f1)\n",
    "    all_precision.append(best_precision)\n",
    "\n",
    "    print(f'pos/neg ratio 1/{n_times_as_many_pos_test_edges}:')\n",
    "    print(f'AUC score: {auc}')\n",
    "    print(f'Best F1 score: {best_f1}')\n",
    "    print(f'Precision for best F1 score: {best_precision}')\n",
    "    print('=============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6671611928989968,\n",
       " 0.6679616378992285,\n",
       " 0.6675719742783746,\n",
       " 0.6665060046712902]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.item() for x in all_auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.4, 0.5, 0.6666666666666666]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.item() for x in all_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.25, 0.3333333333333333, 0.5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.item() for x in all_precision]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_on_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
