{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>Supplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>AAPICO Hitech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>ABC Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>Adient plc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>AGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>Aisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51358</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>voestalpine Rotec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51359</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Xiangyang Sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51360</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yakumo Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51361</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yamashita Rubber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51362</th>\n",
       "      <td>Unipres</td>\n",
       "      <td>Yoshino Press</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51363 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer              Supplier\n",
       "0        Volvo         AAPICO Hitech\n",
       "1        Volvo      ABC Technologies\n",
       "2        Volvo            Adient plc\n",
       "3        Volvo                   AGC\n",
       "4        Volvo                 Aisin\n",
       "...        ...                   ...\n",
       "51358  Unipres     voestalpine Rotec\n",
       "51359  Unipres     Xiangyang Sunrise\n",
       "51360  Unipres  Yakumo Manufacturing\n",
       "51361  Unipres      Yamashita Rubber\n",
       "51362  Unipres         Yoshino Press\n",
       "\n",
       "[51363 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/edges.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_suppliers = set(df['Customer'].tolist() + df['Supplier'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15027"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_suppliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nametoi = {name: i for i, name in enumerate(all_suppliers)}\n",
    "edges = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    supplier1, supplier2 = row\n",
    "    idx1, idx2 = nametoi[supplier1], nametoi[supplier2]\n",
    "    edges.append((idx1, idx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.diameter(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances between all node pairs\n",
    "distances = dict(nx.all_pairs_shortest_path_length(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_pairs = {}\n",
    "for node1, nbs in distances.items():\n",
    "    for node2, distance in nbs.items():\n",
    "        distance_pairs[(min(node1, node2), max(node1, node2))] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(distance_pairs, '../data/distance_pairs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5027000e+04, 4.8261000e+04, 0.0000000e+00, 1.1527360e+07,\n",
       "        0.0000000e+00, 5.9811289e+07, 4.0057711e+07, 0.0000000e+00,\n",
       "        1.4525600e+06, 6.7000000e+02]),\n",
       " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(distance_pairs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = [], []\n",
    "\n",
    "for pair, distance in distance_pairs.items():\n",
    "    if distance == 1:\n",
    "        pos.append(pair)\n",
    "    if distance > 1:\n",
    "        neg.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48,261 positive edges, and 112,849,590 negative edges\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(pos):,} positive edges, and {len(neg):,} negative edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, the authors trained the model with $1:1$ link/non-link ratio, and these ratios for test are $1:1/2/3/4$.\n",
    "\n",
    "Therefore, we will need $24,130$ positive samples and the same amount in negative samples for training.\n",
    "\n",
    "For testing, we need $24,130$ positive samples, and $24,130*4=96,520$ negative samples.\n",
    "\n",
    "In total, we will need $24,130*4=120,650$ negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_SIZE = 24_130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120650"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_subset = neg[::len(neg)//(POSITIVE_SIZE*5)][:POSITIVE_SIZE*5]\n",
    "len(neg_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the paper, each node will be assigned a color using this formula:\n",
    "\n",
    "$$\n",
    "f_{l}(i) = 1 + \\min(d_x, d_y) + \\frac{d}{2} \\left[\\frac{d}{2} + (d \\% 2) - 1 \\right]\n",
    "$$\n",
    "\n",
    "where *i* is a neighbouring node, *x* and *y* are the pair of nodes under consideration, $d_x$ and $d_y$ are shortest paths between *i* and *x*, *y*, respectively, and $d = d_x + d_y$.\n",
    "\n",
    "We will now write a function to calculate this color, given *i*, *x* and *y*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(n1, n2):\n",
    "    n1, n2 = min(n1, n2), max(n1, n2)\n",
    "    return distance_pairs[(n1, n2)]\n",
    "\n",
    "\n",
    "def get_color(i, x, y):\n",
    "    dx, dy = get_distance(i, x), get_distance(i, y)\n",
    "    d = dx + dy\n",
    "    color = 1 + min(dx, dy) + d/2 * (d/2 + d%2 - 1)\n",
    "    \n",
    "    # in the paper, the authors do not apply this *4 step. \n",
    "    # But if not, how will they do the one-hot encoding\n",
    "    # when the color is a float (e.g. 4.25)?\n",
    "    return int(color * 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the color of every 1-hop neighbors for all the positive and negative pairs.\n",
    "\n",
    "The authors used $64$ as maximum size of the one-hot embedding, and also the size of the subgraph embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COLOR = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency list:\n",
    "from collections import defaultdict\n",
    "adj_list = defaultdict(list)\n",
    "\n",
    "for node1, node2 in edges:\n",
    "    if node1 not in adj_list[node2]:\n",
    "        adj_list[node2].append(node1)\n",
    "    if node2 not in adj_list[node1]:\n",
    "        adj_list[node1].append(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_pair(pair):\n",
    "    node1, node2 = pair\n",
    "\n",
    "    subgraph_nodes = set(adj_list[node1] + adj_list[node2])\n",
    "    subgraph_nodes.discard(node1)\n",
    "    subgraph_nodes.discard(node2)\n",
    "    subgraph_nodes_to_idx = {node:i for i, node in enumerate(subgraph_nodes)}\n",
    "\n",
    "    subgraph_edge_idx = []\n",
    "    for subgraph_node in subgraph_nodes:\n",
    "        nbs = adj_list[subgraph_node]\n",
    "        for nb in nbs:\n",
    "            edge = [subgraph_node, nb]\n",
    "            if (\n",
    "                node1 in edge or node2 in edge or # not counting the link containing the target nodes\n",
    "                nb not in subgraph_nodes\n",
    "            ): \n",
    "                continue\n",
    "            subgraph_edge_idx.append([\n",
    "                subgraph_nodes_to_idx[subgraph_node],\n",
    "                subgraph_nodes_to_idx[nb],\n",
    "            ])\n",
    "\n",
    "    subgraph_edge_idx = torch.tensor(subgraph_edge_idx).t()\n",
    "\n",
    "    one_hot_colors = []\n",
    "    for subgraph_node in subgraph_nodes:\n",
    "        color = get_color(subgraph_node, node1, node2)\n",
    "        one_hot_color = [0] * MAX_COLOR\n",
    "        one_hot_color[color] = 1\n",
    "        one_hot_colors.append(one_hot_color)\n",
    "\n",
    "    return torch.tensor(one_hot_colors), subgraph_edge_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_from_node_pairs(pairs, labels):\n",
    "    dataset = []\n",
    "    for pair, label in tqdm(zip(pairs, labels)):\n",
    "        subgraph_node_features, subgraph_edge_idx = process_data_pair(pair)\n",
    "        data = Data(\n",
    "            x=subgraph_node_features, \n",
    "            edge_index=subgraph_edge_idx,\n",
    "            y=torch.tensor([label])\n",
    "        )\n",
    "        dataset.append(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48260it [05:55, 135.65it/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_data_from_node_pairs(\n",
    "    pairs=pos[:POSITIVE_SIZE] + neg_subset[:POSITIVE_SIZE],\n",
    "    labels=[1.0]*POSITIVE_SIZE + [0.0]*POSITIVE_SIZE\n",
    ")\n",
    "torch.save(train_dataset, '../data/train_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset_1_1 = create_data_from_node_pairs(\n",
    "#     pairs=pos[POSITIVE_SIZE:] + neg_subset[POSITIVE_SIZE:POSITIVE_SIZE*2],\n",
    "#     labels=[1.0]*POSITIVE_SIZE + [0.0]*POSITIVE_SIZE\n",
    "# )\n",
    "# torch.save(test_dataset_1_1, '../data/test_dataset_1_1.pt')\n",
    "\n",
    "# test_dataset_1_2 = test_dataset_1_1 + create_data_from_node_pairs(\n",
    "#     pairs=neg_subset[POSITIVE_SIZE*2:POSITIVE_SIZE*3],\n",
    "#     labels=[0.0]*POSITIVE_SIZE\n",
    "# )\n",
    "# torch.save(test_dataset_1_2, '../data/test_dataset_1_2.pt')\n",
    "\n",
    "# test_dataset_1_3 = test_dataset_1_2 + create_data_from_node_pairs(\n",
    "#     pairs=neg_subset[POSITIVE_SIZE*3:POSITIVE_SIZE*4],\n",
    "#     labels=[0.0]*POSITIVE_SIZE\n",
    "# )\n",
    "# torch.save(test_dataset_1_3, '../data/test_dataset_1_3.pt')\n",
    "\n",
    "# test_dataset_1_4 = test_dataset_1_3 + create_data_from_node_pairs(\n",
    "#     pairs=neg_subset[POSITIVE_SIZE*4:],\n",
    "#     labels=[0.0]*POSITIVE_SIZE\n",
    "# )\n",
    "# torch.save(test_dataset_1_4, '../data/test_dataset_1_4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torch.load('../data/train_dataset.pt')\n",
    "# test_dataset_1_1 = torch.load('../data/test_dataset_1_1.pt')\n",
    "# test_dataset_1_2 = torch.load('../data/test_dataset_1_2.pt')\n",
    "# test_dataset_1_3 = torch.load('../data/test_dataset_1_3.pt')\n",
    "# test_dataset_1_4 = torch.load('../data/test_dataset_1_4.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is defined as a 3-layer GCN. The input dim , hidden size, and output dim of each layer is equal to the one-hot embedding size.\n",
    "\n",
    "The original paper from Kipf and Welling (2017) used ReLU activation, but in this paper the authors used sigmoid instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BinaryClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CombinedModel(torch.nn.Module):\n",
    "    def __init__(self, gnn_input_dim, gnn_hidden_dim, gnn_output_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.gnn = GNN(gnn_input_dim, gnn_hidden_dim, gnn_output_dim)\n",
    "        self.classifier = BinaryClassifier(gnn_output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        subgraph_embedding = self.gnn(x, edge_index, batch)\n",
    "        output = self.classifier(subgraph_embedding)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CombinedModel(gnn_input_dim=MAX_COLOR, gnn_hidden_dim=MAX_COLOR, gnn_output_dim=MAX_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "model.train()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features (x): tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "Edge index: tensor([[0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 6.7768e+04, 6.7768e+04,\n",
      "         6.7768e+04],\n",
      "        [1.0700e+02, 1.0700e+02, 4.7800e+02,  ..., 6.7766e+04, 6.7768e+04,\n",
      "         6.7767e+04]])\n",
      "Batch vector: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
      "Labels (y): tensor([1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0.])\n",
      "========\n",
      "Node features (x) shape: torch.Size([67769, 64])\n",
      "Edge index shape: torch.Size([2, 308049])\n",
      "Batch vector shape: torch.Size([67769])\n",
      "Labels (y) shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Get a single batch from the train_dataloader\n",
    "for batch in train_dataloader:\n",
    "    print(\"Node features (x):\", batch.x)\n",
    "    print(\"Edge index:\", batch.edge_index)\n",
    "    print(\"Batch vector:\", batch.batch)\n",
    "    print(\"Labels (y):\", batch.y)\n",
    "    print('========')\n",
    "    print(\"Node features (x) shape:\", batch.x.shape)\n",
    "    print(\"Edge index shape:\", batch.edge_index.shape)\n",
    "    print(\"Batch vector shape:\", batch.batch.shape)\n",
    "    print(\"Labels (y) shape:\", batch.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.144327062268362\n",
      "Epoch 2/20, Loss: 0.06858223588076523\n",
      "Epoch 3/20, Loss: 0.06595033247725393\n",
      "Epoch 4/20, Loss: 0.0607922196920429\n",
      "Epoch 5/20, Loss: 0.05822818212279811\n",
      "Epoch 6/20, Loss: 0.05680983578330448\n",
      "Epoch 7/20, Loss: 0.0537508331071684\n",
      "Epoch 8/20, Loss: 0.05244740929745642\n",
      "Epoch 9/20, Loss: 0.052127402753781076\n",
      "Epoch 10/20, Loss: 0.052167425177289145\n",
      "Epoch 11/20, Loss: 0.05037261618463884\n",
      "Epoch 12/20, Loss: 0.04989626576320796\n",
      "Epoch 13/20, Loss: 0.05162426701158029\n",
      "Epoch 14/20, Loss: 0.04880523576376869\n",
      "Epoch 15/20, Loss: 0.04835581797755442\n",
      "Epoch 16/20, Loss: 0.047890308354996684\n",
      "Epoch 17/20, Loss: 0.048371770397499805\n",
      "Epoch 18/20, Loss: 0.04590514804787844\n",
      "Epoch 19/20, Loss: 0.04822772945814505\n",
      "Epoch 20/20, Loss: 0.05174270735206033\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch.x.float(), batch.edge_index.int(), batch.batch)\n",
    "\n",
    "        loss = criterion(output, batch.y.float().unsqueeze(-1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_on_graph_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
